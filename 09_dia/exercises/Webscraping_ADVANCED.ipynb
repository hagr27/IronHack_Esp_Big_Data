{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58922c5-1ff4-4d17-bb24-3807b34ba29b",
   "metadata": {
    "id": "55f44775-459b-4aab-b0cc-ed6d69bd8faf"
   },
   "source": [
    "<h1 style=\"color: #00BFFF;\">Web Scraping with Selenium (advanced)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebde9917-b30a-40c3-ab4a-d6677dc085a5",
   "metadata": {
    "id": "3117eb6b-47f2-4bc0-afb7-04cab8095055"
   },
   "source": [
    "![legtsgo](https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExbzQ4eDdobnZlenhtN3c5MndmcDZpMW4wdXZzZTcxaDl1Zmo2YWt3dSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/SpopD7IQN2gK3qN4jS/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3291a2-5fc6-4e93-b84c-4ef6d45bb433",
   "metadata": {
    "id": "2f3291a2-5fc6-4e93-b84c-4ef6d45bb433"
   },
   "source": [
    "### Exploring Web Page Structures\n",
    "\n",
    "To inspect the underlying HTML of a web page, right-click anywhere on the page. \n",
    "- Choose \"View Page Source\" in browsers like Chrome or Firefox.\n",
    "- For Internet Explorer, choose \"View Source,\" and for Safari, select \"Show Page Source.\"\n",
    "- (In Safari, if this option isn't visible, navigate to Safari Preferences, click on the Advanced tab, and enable \"Show Develop menu in menu bar.\")\n",
    "\n",
    "To embark on your web scraping journey, you just need to grasp **three foundational aspects** of HTML:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d58c48-9b0d-4aa6-8903-e5cf504d16cd",
   "metadata": {
    "id": "70d58c48-9b0d-4aa6-8903-e5cf504d16cd"
   },
   "source": [
    "### Fact 1: HTML is Built on Tags\n",
    "\n",
    "At its core, HTML is composed of content enveloped in `<tags>`. Tags come in various types:\n",
    " * **Headings**: `<h1>`, `<h2>`, `<h3>`, `<h4>`...\n",
    " * **Phrasing**: `<b>`, `<strong>`, `<sub>`, `<i>`, `<a>`...\n",
    " * **Embedded Content**: `<audio>`, `<img>`, `<video>`, `<iframe>`...\n",
    " * **Tabulated Data**: `<table>`, `<tr>`, `<td>`, `<tbody>`...\n",
    " * **Page Sections**: `<header>`, `<section>`, `<nav>`, `<article>`...\n",
    " * **Metadata and Scripts**: `<meta>`, `<title>`, `<script>`, `<link>`..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc87e26-c9b3-42b1-8be6-cabd75da78e5",
   "metadata": {
    "id": "fcc87e26-c9b3-42b1-8be6-cabd75da78e5"
   },
   "source": [
    "### Fact 2: Tags Can Have Attributes\n",
    "\n",
    "HTML tags can possess \"attributes,\" which are defined within the opening tag itself. Examine the following example:\n",
    "- `<a class=\"text-monospace\" id=\"name_132\" href=\"http://www.example.com\"> Page Content </a>\n",
    "`: This `div` tag encompasses the following attributes:\n",
    "    + `class`: With the value \"text-monospace\". Remember, the class isn't unique across the page.\n",
    "    + `id`: With the value \"name_132\". IDs are meant to be unique identifiers for tags on the page.\n",
    "    + `href`: With the value www.example.com. The href commonly represents a link to another section of the page or to an external website.\n",
    "\n",
    "**Key Notes**:\n",
    "- The `id` attribute should be unique for a tag; no two tags should share the same `id`.\n",
    "- The `class` attribute isn't meant to be unique. Instead, it often groups tags exhibiting similar behavior or styles.\n",
    "\n",
    "For web scraping purposes, **understanding the semantics** behind terms like `<span>`, `class`, or `short-desc` **isn't crucial**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02985a03-251a-4fa7-b969-4afa023cdc6a",
   "metadata": {
    "id": "02985a03-251a-4fa7-b969-4afa023cdc6a"
   },
   "source": [
    "\n",
    "### Fact 3: Tags Can Be Nested\n",
    "\n",
    "Imagine the following segment of HTML code:\n",
    "\n",
    "`Hello <strong><em>Ironhack</em> students</strong>`\n",
    "\n",
    "Here, the phrase **Ironhack students** would be displayed in bold since it resides between the `<strong>` and `</strong>` tags. Additionally, the word ***Ironhack*** would be italicized due to the `<em>` tag, which signifies italic formatting. However, the word \"Hello\" remains unaffected by any formatting, as it lies outside both the `<strong>` and `<em>` tags. This results in the display:\n",
    "\n",
    "Hello ***Ironhack* students**\n",
    "\n",
    "This example illustrates a key principle: **tags influence the text from their opening to their closing points,** even if they are nested within other tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575aadd7-e54f-4751-ba64-cd660110213a",
   "metadata": {
    "id": "575aadd7-e54f-4751-ba64-cd660110213a"
   },
   "source": [
    "### Selecting Specific Elements in Web Scraping\n",
    "\n",
    "When diving into web scraping, it's essential to target specific elements efficiently. To hone in on the precise content you need, consider filtering tags based on:\n",
    "\n",
    " * **Tag Name**: The main type of the element (e.g., `<div>`, `<a>`, `<p>`).\n",
    " * **Class**: A descriptor that groups multiple elements with similar characteristics.\n",
    " * **ID**: A unique identifier assigned to a particular element.\n",
    " * **Other Attributes**: Additional properties like `href`, `title`, or `lang` that can further specify the elements of interest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7813165d",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #00BFFF;\">00 | Use case: Indeed Jobs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acbe4791-34a0-46a7-9093-7f732a649e60",
   "metadata": {
    "id": "yVB5PyUKaAbi"
   },
   "outputs": [],
   "source": [
    "# üìö Basic libraries\n",
    "import pandas as pd\n",
    "\n",
    "#‚ùóNew Libraries !\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fd6dfc-8f4c-4a77-b34f-abb3d96906c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Settings\n",
    "pd.set_option('display.max_columns', None) # display all columns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # ignore warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a4aaf-8ef5-44bc-b215-0cd63479ac88",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #00BFFF;\">01 | Data Extraction</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff65d92-1661-4f24-b4fd-4a9309c3b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://es.indeed.com/jobs?q=data+analyst+junior&l=&from=searchOnHP&vjk=ad48ee37bc54e63e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "686f9a9c-0b9b-473d-bdcc-709843009cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b1917-78f7-4b25-a408-96339729db93",
   "metadata": {
    "id": "fea668ac-cc99-40dc-976b-354390ef99c7"
   },
   "source": [
    "### How to Solve a 403 Error\n",
    "\n",
    "When you get a `403` status code in response to a web request, it means \"Forbidden.\" The server understands your request, but it refuses to fulfill it. This is often a measure by websites to prevent web scraping or automated access.\n",
    "\n",
    "Here's why you might get a `403 Forbidden` error:\n",
    "\n",
    "1. **User-Agent**: Many websites block requests that don't have a standard web browser User-Agent. The default User-Agent of the `requests` library often gets blocked.\n",
    "2. **Robots.txt**: This is a file websites use to guide web crawlers about which pages or sections of the site shouldn't be processed or scanned. Respect it.\n",
    "3. **Rate Limiting**: Websites might block you if you make too many requests in a short period.\n",
    "And more...\n",
    "\n",
    "To solve it, try the following, starting from the user-agent:\n",
    "\n",
    "1. **Change the User-Agent**:\n",
    "   You can mimic a request from a web browser by setting a User-Agent header.\n",
    "   ```python\n",
    "   headers = {\n",
    "       \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "   }\n",
    "   response = requests.get(url, headers=headers)\n",
    "   ```\n",
    "\n",
    "2. **Use a Web Scraper Library**:\n",
    "   Libraries like Scrapy or Selenium can help bypass restrictions, especially when JavaScript rendering is involved.\n",
    "\n",
    "3. **Respect `robots.txt`**:\n",
    "   Always check `https://www.example.com/robots.txt` (replace `example.com` with the website's domain) to see which URLs you're allowed to access.\n",
    "\n",
    "4. **Rate Limiting**:\n",
    "   Implement delays in your requests using `time.sleep(seconds)` to avoid hitting rate limits.\n",
    "\n",
    "5. **Use Proxies or VPN**:\n",
    "   Rotate IP addresses or use a VPN service if the server has blocked your IP.\n",
    "\n",
    "6. **Sessions & Cookies**:\n",
    "   Some websites might require maintaining sessions or handling cookies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c6cf6-71da-43b2-96d9-cbfb09f823d4",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #00BFFF;\">00 | Advanced Use case: Linkedin Jobs using Selenium</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a7da7ca-e0ec-4f49-acba-77a050a87183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install selenium --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e858bb-fb26-436b-bae5-ea3b57c07df9",
   "metadata": {
    "id": "yVB5PyUKaAbi"
   },
   "outputs": [],
   "source": [
    "# üìö Basic libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#‚ùóNew Libraries !\n",
    "import time\n",
    "from getpass import getpass # to safely storage your password\n",
    "# selenium libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4dba89-ace3-44f3-9f40-090ff36670b1",
   "metadata": {},
   "source": [
    "### Code Breakdown\n",
    "\n",
    "```python\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import random\n",
    "from getpass import getpass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4606f3d-a607-4b9f-88c9-b8941a2a6376",
   "metadata": {},
   "source": [
    "### Imports:\n",
    "- **webdriver**: The main module from Selenium that allows controlling the browser.\n",
    "- **Service**: Used to set up the ChromeDriver service.\n",
    "- **ChromeDriverManager**: Manages and installs the ChromeDriver automatically.\n",
    "- **By**: Provides methods for locating elements in a webpage (like IDs, classes, etc.).\n",
    "- **time**, **random**: Used to add delays (for mimicking human behavior).\n",
    "- **getpass**: Allows securely getting the password input without displaying it on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df9dc929-c149-4c2c-bf7e-6b9dab191e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Settings\n",
    "pd.set_option('display.max_columns', None) # display all columns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # ignore warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b04aa2-7859-498e-9f8c-d2a32338f684",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #00BFFF;\">01 | Data Extraction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d26e7-02e6-45e3-bbd4-60bcf9c2d6ca",
   "metadata": {},
   "source": [
    "In web scraping, **WebDriver** is a tool that automates browsers, allowing you to interact with web pages just like a human would. It‚Äôs commonly used in conjunction with **Selenium**, a popular browser automation library. \n",
    "\n",
    "The WebDriver works by controlling the browser (e.g., Chrome, Firefox) and simulating user actions such as clicking buttons, filling out forms, and navigating web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13933bd7-9aa1-4352-95fe-2393a00bbe5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "error",
     "timestamp": 1695747793332,
     "user": {
      "displayName": "Susan Ndinoshinge",
      "userId": "16659780857992036365"
     },
     "user_tz": -120
    },
    "id": "I5HHJRnxR9WA",
    "outputId": "e8617a80-9fb2-41b5-f3b7-246d5eeff06b"
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cc86cd6-b0ec-474d-952f-3ac4f5381b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the website\n",
    "driver.get('https://www.linkedin.com/login/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd6866-79f0-4523-98f7-e9bcb96eb30c",
   "metadata": {
    "id": "5Z3jz26TYw2j"
   },
   "outputs": [],
   "source": [
    "# Add email\n",
    "email = input('Enter your email: ')\n",
    "\n",
    "# Find email box\n",
    "email_box = driver.find_element(By.ID, \"username\")\n",
    "\n",
    "# Clear email box\n",
    "email_box.clear()\n",
    "\n",
    "# Input password into browser\n",
    "email_box.send_keys(email)\n",
    "\n",
    "# Add sleeping time to mimic human behaviour\n",
    "time.sleep(random.random() * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15eb3b-0c37-4932-a7bc-979fcf3df96e",
   "metadata": {
    "id": "7qZnNO0wYw2j"
   },
   "outputs": [],
   "source": [
    "# Add password\n",
    "password = getpass('Enter your password: ')\n",
    "\n",
    "# Find password box\n",
    "pass_box = driver.find_element(By.ID, \"password\")\n",
    "\n",
    "# Clear password box\n",
    "pass_box.clear()\n",
    "\n",
    "# Input password into browser\n",
    "pass_box.send_keys(password)\n",
    "\n",
    "# Add sleeping time to mimic human behaviour\n",
    "time.sleep(random.random() * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157afcb-fd82-41b9-a478-a1800b59ef44",
   "metadata": {
    "id": "lKpjIOqFYw2k"
   },
   "outputs": [],
   "source": [
    "# Find and click on the log-in button\n",
    "login = driver.find_element(By.CLASS_NAME, 'login__form_action_container')\n",
    "login.click()\n",
    "time.sleep(random.random() * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20296b-2af6-4747-84f2-6454e60db503",
   "metadata": {
    "id": "ghIm1vlzJXLz"
   },
   "outputs": [],
   "source": [
    "# Add exception handling\n",
    "try:\n",
    "    login = driver.find_element(By.CLASS_NAME, 'login__form_action_container')\n",
    "    login.click()\n",
    "    time.sleep(random.random() * 3)\n",
    "except NoSuchElementException:\n",
    "    print(\"Log-in already done!\")\n",
    "except Exception as e:\n",
    "    print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da40d0e-6763-486a-9567-f8653ec2bc45",
   "metadata": {
    "id": "b9ee3a68-412e-44f1-9422-e53fbea4ce66"
   },
   "source": [
    "<h2 style=\"color: #008080;\">Final job position</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264206e8-8140-480a-9b40-927780827f3d",
   "metadata": {
    "id": "bQEVcYPmR9WE"
   },
   "outputs": [],
   "source": [
    "# Go to job search bar\n",
    "try:\n",
    "    job_icon = driver.find_element(By.CSS_SELECTOR, \"span[title='Jobs']\")\n",
    "    job_icon.click()\n",
    "    time.sleep(random.random() * 3)\n",
    "except ElementClickInterceptedException:\n",
    "    print(\"Element not displayed by JS. Try zooming in or resizing the window\")\n",
    "except Exception as e:\n",
    "    print(repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925aae58-1163-4f74-81f7-6e9af5e6cd6f",
   "metadata": {
    "id": "IdY-6iaPYw2l"
   },
   "outputs": [],
   "source": [
    "# Zooming in\n",
    "driver.execute_script(\"document.body.style.zoom='200%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1572ed-093d-4df3-924c-a23c49dabf10",
   "metadata": {
    "id": "4A5GKTKZYw2l"
   },
   "outputs": [],
   "source": [
    "# Zooming out\n",
    "driver.execute_script(\"document.body.style.zoom='67%'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cff0ae-d349-4021-887d-248b55a5c98e",
   "metadata": {
    "id": "b9ee3a68-412e-44f1-9422-e53fbea4ce66"
   },
   "source": [
    "<h2 style=\"color: #008080;\">Type of job</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5b2e6-5c40-4534-a50e-dc76c8666c75",
   "metadata": {
    "id": "8tsjAlTbYw2l"
   },
   "outputs": [],
   "source": [
    "# Optional - Change window size\n",
    "# driver.set_window_size(800, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e1168-68f9-4f76-adc0-4dae79e08211",
   "metadata": {
    "id": "aksOK7YbR9WF"
   },
   "outputs": [],
   "source": [
    "search_job = driver.find_elements(By.CLASS_NAME,'jobs-search-box__text-input')[0]\n",
    "job = input('What job do you want to search for: ')\n",
    "search_job.clear()\n",
    "search_job.send_keys(job)\n",
    "time.sleep(random.random() * 3)\n",
    "\n",
    "# Go to the location tab\n",
    "search_job.send_keys(Keys.TAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9cd51-6a8a-497c-9052-b79c02c1ca04",
   "metadata": {
    "id": "b9ee3a68-412e-44f1-9422-e53fbea4ce66"
   },
   "source": [
    "<h2 style=\"color: #008080;\">Job location</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd764b-f244-4173-b92d-f3bebaead274",
   "metadata": {
    "id": "xqHdk1eJR9WG"
   },
   "outputs": [],
   "source": [
    "location_box = driver.switch_to.active_element\n",
    "location = input('Where do you want to search for jobs: ')\n",
    "location_box.send_keys(location)\n",
    "time.sleep(random.random() * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bc08a-3430-409f-9e66-95fe3de2450e",
   "metadata": {
    "id": "oehwUBoFR9WH"
   },
   "outputs": [],
   "source": [
    "# Now let's search\n",
    "location_box.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6d3c9-1c63-4fc9-9550-5378b041ea2d",
   "metadata": {
    "id": "gCvypbbnR9WI"
   },
   "outputs": [],
   "source": [
    "# Maximize the window - useful to see all the elements as the page is dynamic\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7a400-9776-42e5-a225-06d7278fd3ad",
   "metadata": {
    "id": "ZLcFYxe5Yw2m"
   },
   "outputs": [],
   "source": [
    "## Optional: you can also fullscreen the window\n",
    "# driver.fullscreen_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ba8d1-7979-4aaa-b57b-b6fef5aca501",
   "metadata": {
    "id": "b9ee3a68-412e-44f1-9422-e53fbea4ce66"
   },
   "source": [
    "<h2 style=\"color: #008080;\">Scraping from HTML</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e2697-b233-45b2-87ef-63407b74f00a",
   "metadata": {
    "id": "CR1rjMlpYw2n"
   },
   "source": [
    "As mentioned previously, Selenium can be quite slow, so we'd always want to check whether we can fetch our data directly using static web scraping tools (i.e. `requests`, `BeautifulSoup`, `scrapy`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c9046-0f03-4e21-bf91-bee4ef659db0",
   "metadata": {
    "id": "INf0pzQGYw2n"
   },
   "outputs": [],
   "source": [
    "# Check if the source code contains the job listings\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html)\n",
    "soup.find_all(attrs={'class': re.compile(r'job-card-list__title')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d4641-96cc-4cde-a777-01dbefcb8d4b",
   "metadata": {
    "id": "P_3q4qSpYw2n"
   },
   "outputs": [],
   "source": [
    "# Clean the list\n",
    "job_list_dirty = soup.find_all(attrs={'class': re.compile(r'job-card-list__title')})\n",
    "job_list_clean = [job.text.strip() for job in job_list_dirty]\n",
    "job_list_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f33dd-54b4-4d65-960a-55c895e5b5f2",
   "metadata": {
    "id": "LXkkkJavYw2o"
   },
   "outputs": [],
   "source": [
    "# Do the same for the company\n",
    "job_company_dirty = soup.find_all('div', attrs={'class': re.compile(r'^artdeco-entity-lockup__subtitle')})\n",
    "job_company_clean = [company.text.strip() for company in job_company_dirty]\n",
    "job_company_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5faf9-8031-41a5-a702-ccd0ad527cdc",
   "metadata": {
    "id": "kAo_dkNwYw2o"
   },
   "outputs": [],
   "source": [
    "# Make it into a dataset\n",
    "data = zip(job_list_clean, job_company_clean)\n",
    "df = pd.DataFrame(data, columns=['Job', 'Company'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885815e7-c359-4ed2-95b4-bf8e11be3ecb",
   "metadata": {
    "id": "qWHncrUpYw2o"
   },
   "outputs": [],
   "source": [
    "# Great, let's now create a function out of this:\n",
    "def get_job_postings(driver, page):\n",
    "\n",
    "     # Zoom in 100% to ensure all HTML is loaded\n",
    "     driver.execute_script(\"document.body.style.zoom='100%'\")\n",
    "\n",
    "     # Go to bottom of page to retrieve all job postings\n",
    "     page.send_keys(Keys.END)\n",
    "     page.send_keys(Keys.CONTROL + Keys.HOME) # combination of the two keys brings you to the top of the element\n",
    "\n",
    "     # Parse HTML\n",
    "     html = driver.page_source\n",
    "     soup = BeautifulSoup(html)\n",
    "\n",
    "     # Get jobs\n",
    "     job_list_dirty = soup.find_all(attrs={'class': re.compile(r'job-card-list__title')})\n",
    "     job_list_clean = [job.text.strip() for job in job_list_dirty]\n",
    "\n",
    "     # Get companies\n",
    "     job_company_dirty = soup.find_all('div', attrs={'class': re.compile(r'^artdeco-entity-lockup__subtitle')})\n",
    "     job_company_clean = [company.text.strip() for company in job_company_dirty]\n",
    "\n",
    "     # Convert data in to dataframe\n",
    "     data = zip(job_list_clean, job_company_clean)\n",
    "     return pd.DataFrame(data, columns=['Job', 'Company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eceba4a-d483-4a4b-b250-bf901caba156",
   "metadata": {
    "id": "_FxEM_9CYw2p"
   },
   "outputs": [],
   "source": [
    "page = driver.find_element(By.CSS_SELECTOR,\"a[class^='disabled ember-view']\")\n",
    "get_job_postings(driver, page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab63d4e0-7248-4496-9690-2c62e60d1c76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d096e82-bedc-43b7-aac5-a6d9241dc270",
   "metadata": {
    "id": "3ZNZ485GYw2q"
   },
   "outputs": [],
   "source": [
    "# Get a list with the buttons in the page\n",
    "def get_buttons(page):\n",
    "    buttons = []\n",
    "    for button in page.find_elements(By.XPATH, \"//ul/li/button\"):\n",
    "        try:\n",
    "            int(button.text)\n",
    "            buttons.append(button)\n",
    "        except:\n",
    "            pass\n",
    "    return buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4c724-f96c-4b45-836d-583cffff7c5c",
   "metadata": {
    "id": "9xUb-vkJYw2q"
   },
   "outputs": [],
   "source": [
    "# Get the number of pages to scrape\n",
    "current_page = driver.find_element(By.CSS_SELECTOR,\"a[class^='disabled ember-view']\")\n",
    "buttons = get_buttons(current_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef111953-37b9-42e1-9c22-3bae66b93879",
   "metadata": {
    "id": "b9ee3a68-412e-44f1-9422-e53fbea4ce66"
   },
   "source": [
    "<h2 style=\"color: #008080;\">Final DataFrame</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1923a4c-60c6-4cca-87fa-1ed993f4986b",
   "metadata": {
    "id": "6Ckxwa06Yw2r"
   },
   "outputs": [],
   "source": [
    "# Loop through pages and save results in a dataframe\n",
    "df = pd.DataFrame()\n",
    "driver.execute_script(\"document.body.style.zoom='100%'\")\n",
    "\n",
    "for i in range(len(buttons)):\n",
    "    # Printing the button number for debugging purposes\n",
    "    print(i)\n",
    "\n",
    "    # Extract posts from current page\n",
    "    current_page = driver.find_element(By.CSS_SELECTOR,\"a[class^='disabled ember-view']\")\n",
    "    postings = get_job_postings(driver, current_page)\n",
    "\n",
    "    # Refresh button list (if you don't the code will throw an exception.. trust me I spent half an hour debugging it)\n",
    "    current_buttons = get_buttons(current_page)\n",
    "\n",
    "    # Add to dataframe\n",
    "    df = pd.concat([df, postings], axis=0)\n",
    "\n",
    "    # Go to the next page\n",
    "    current_buttons[i].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb5e1c-c96e-4afd-8f1d-d5930d57e2db",
   "metadata": {
    "id": "czjvtbmgYw2r"
   },
   "outputs": [],
   "source": [
    "# Check dataframe\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078a46a-91e2-4d1d-86f7-bcd5309c9278",
   "metadata": {
    "id": "ab3be533-4200-4546-a20c-1627834548eb",
    "tags": []
   },
   "source": [
    "<h2 style=\"color: #008080;\">Summary</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7881da9c-3b61-4bd7-acf1-9ff26b54cc5b",
   "metadata": {
    "id": "000a20c0-ea4e-4065-9958-426c9355de3a"
   },
   "source": [
    "It's always recommended to check for the availability of an **API** before resorting to web scraping for the following reasons:\n",
    " * It is generally much easier to use\n",
    " * APIs are usually well-documented\n",
    " * Utilizing APIs is often preferred by server administrators\n",
    "\n",
    "Refer to the `robots.txt` file on a website (by doing `www.example.com/robots.txt`) to understand the server's guidelines and limitations regarding web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abcfa94-415b-4991-9abb-5a355d6f5c35",
   "metadata": {
    "id": "d9dcaa18-38d3-47fa-a890-15320b61237c"
   },
   "source": [
    "1. **Web Technologies**:\n",
    "   - **HTML**: This is the standard markup language that holds the content of the webpage. It is the primary target when we engage in web scraping.\n",
    "   - **CSS**: Cascading Style Sheets are used to describe the look and formatting of a document written in HTML.\n",
    "   - **JavaScript**: This is a scripting language used to create and interactive and dynamic website content.\n",
    "\n",
    "2. **HTML Structure**:\n",
    "   - **Hierarchical**: HTML documents are structured hierarchically, meaning elements are nested within other elements, forming a tree-like structure.\n",
    "   - **Tags**: These are the building blocks of HTML, defining elements that hold different types of content.\n",
    "   - **Attributes**: HTML tags can have attributes, which define properties of an element and are used to set various characteristics such as class, ID, and style.\n",
    "\n",
    "3. **Web Scraping Tools**:\n",
    "   - **Requests**: A Python library that allows you to send HTTP requests to get the HTML content of a webpage.\n",
    "   - **Beautiful Soup**: A Python library that facilitates the programmatic analysis of HTML, helping in parsing the HTML and navigating the parse tree.\n",
    "   - **Selenium**: In cases where the webpage content is dynamic and generated using JavaScript, tools like Selenium are often used. Selenium can interact with JavaScript to load dynamic content, making it accessible for scraping.\n",
    "   \n",
    "4. **Finding and Selecting Elements**:\n",
    "   - **Selection by Tag, Class, and ID**: We can find elements using various attributes such as their tag name, class name, or ID.\n",
    "   - **CSS Selectors**: These are patterns used to select elements more complexly, leveraging the relationships between different elements to find them in numerous ways.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06248492-8187-4987-9c06-9826b29bf764",
   "metadata": {
    "id": "321d0724-3854-4414-98b5-569fea8296d5",
    "tags": []
   },
   "source": [
    "<h2 style=\"color: #008080;\">Further materials</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede0609-efcf-46a3-b06c-23e7acc79e55",
   "metadata": {
    "id": "e582b62b-77c5-4ee9-8c32-d005786bf408"
   },
   "source": [
    "[Web archive](http://web.archive.org/): Find the historical state of webpages in the past!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
